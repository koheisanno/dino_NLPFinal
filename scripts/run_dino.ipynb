{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIBWTQ3H-zxu",
        "outputId": "e5d08827-07c0-46fa-ec01-fc4790089561"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'dino_NLPFinal'...\n",
            "remote: Enumerating objects: 124, done.\u001b[K\n",
            "remote: Counting objects: 100% (64/64), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 124 (delta 36), reused 39 (delta 25), pack-reused 60\u001b[K\n",
            "Receiving objects: 100% (124/124), 89.54 KiB | 1.38 MiB/s, done.\n",
            "Resolving deltas: 100% (50/50), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/koheisanno/dino_NLPFinal.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "-HG_osqlZ336",
        "outputId": "cd71a464-ce5c-4a3f-9a69-80e529c92b9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed May  1 02:12:57 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA L4                      Off | 00000000:00:03.0 Off |                    0 |\n",
            "| N/A   32C    P8              11W /  72W |      1MiB / 23034MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNbsBALH-4JT",
        "outputId": "2afa628c-f35d-4147-e21c-22961ab10f46"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd dino_NLPFinal/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPC7KzFh-_ev",
        "outputId": "8bed9566-240a-42c3-cb92-dff2dc693666"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dino_NLPFinal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull https://github.com/koheisanno/dino_NLPFinal.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taZ4s5WM_CYD",
        "outputId": "6404aceb-30a2-412a-e326-57d40f885726"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects:  20% (1/5)\u001b[K\rremote: Counting objects:  40% (2/5)\u001b[K\rremote: Counting objects:  60% (3/5)\u001b[K\rremote: Counting objects:  80% (4/5)\u001b[K\rremote: Counting objects: 100% (5/5)\u001b[K\rremote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 3 (delta 2), reused 3 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects:  33% (1/3)\rUnpacking objects:  66% (2/3)\rUnpacking objects: 100% (3/3)\rUnpacking objects: 100% (3/3), 385 bytes | 385.00 KiB/s, done.\n",
            "From https://github.com/koheisanno/dino_NLPFinal\n",
            " * branch            HEAD       -> FETCH_HEAD\n",
            "Updating d826305..0b0d635\n",
            "Fast-forward\n",
            " dino.py | 12 \u001b[32m++++++++++\u001b[m\u001b[31m--\u001b[m\n",
            " 1 file changed, 10 insertions(+), 2 deletions(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements3.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8OKaKz4L_FdX",
        "outputId": "c8e1a5c4-4257-4c91-d9b3-25c37d33c87c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets==2.19.0 (from -r requirements3.txt (line 1))\n",
            "  Downloading datasets-2.19.0-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy==1.24.4 (from -r requirements3.txt (line 2))\n",
            "  Downloading numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai==1.23.2 (from -r requirements3.txt (line 3))\n",
            "  Downloading openai-1.23.2-py3-none-any.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn==1.3.2 (from -r requirements3.txt (line 4))\n",
            "  Downloading scikit_learn-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m92.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy==1.10.1 (from -r requirements3.txt (line 5))\n",
            "  Downloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentence-transformers==2.7.0 (from -r requirements3.txt (line 6))\n",
            "  Downloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch==2.2.2 (from -r requirements3.txt (line 7))\n",
            "  Downloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.17.2 (from -r requirements3.txt (line 8))\n",
            "  Downloading torchvision-0.17.2-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m98.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm==4.66.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements3.txt (line 9)) (4.66.2)\n",
            "Collecting transformers==4.40.0 (from -r requirements3.txt (line 10))\n",
            "  Downloading transformers-4.40.0-py3-none-any.whl (9.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m120.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.0->-r requirements3.txt (line 1)) (3.13.4)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.0->-r requirements3.txt (line 1)) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.0->-r requirements3.txt (line 1)) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets==2.19.0->-r requirements3.txt (line 1))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.0->-r requirements3.txt (line 1)) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.0->-r requirements3.txt (line 1)) (2.31.0)\n",
            "Collecting xxhash (from datasets==2.19.0->-r requirements3.txt (line 1))\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets==2.19.0->-r requirements3.txt (line 1))\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.0->-r requirements3.txt (line 1)) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.0->-r requirements3.txt (line 1)) (3.9.5)\n",
            "Collecting huggingface-hub>=0.21.2 (from datasets==2.19.0->-r requirements3.txt (line 1))\n",
            "  Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.0->-r requirements3.txt (line 1)) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.0->-r requirements3.txt (line 1)) (6.0.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.23.2->-r requirements3.txt (line 3)) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.23.2->-r requirements3.txt (line 3)) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai==1.23.2->-r requirements3.txt (line 3))\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.23.2->-r requirements3.txt (line 3)) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.23.2->-r requirements3.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai==1.23.2->-r requirements3.txt (line 3)) (4.11.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.2->-r requirements3.txt (line 4)) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.2->-r requirements3.txt (line 4)) (3.4.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.7.0->-r requirements3.txt (line 6)) (9.4.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->-r requirements3.txt (line 7)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->-r requirements3.txt (line 7)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->-r requirements3.txt (line 7)) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.2->-r requirements3.txt (line 7))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.2->-r requirements3.txt (line 7))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.2->-r requirements3.txt (line 7))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.2->-r requirements3.txt (line 7))\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.2->-r requirements3.txt (line 7))\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.2->-r requirements3.txt (line 7))\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.2->-r requirements3.txt (line 7))\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.2->-r requirements3.txt (line 7))\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.2->-r requirements3.txt (line 7))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.2->-r requirements3.txt (line 7))\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.2->-r requirements3.txt (line 7))\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->-r requirements3.txt (line 7)) (2.2.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0->-r requirements3.txt (line 10)) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0->-r requirements3.txt (line 10)) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0->-r requirements3.txt (line 10)) (0.4.3)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2->-r requirements3.txt (line 7))\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.23.2->-r requirements3.txt (line 3)) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.23.2->-r requirements3.txt (line 3)) (1.2.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.19.0->-r requirements3.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.19.0->-r requirements3.txt (line 1)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.19.0->-r requirements3.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.19.0->-r requirements3.txt (line 1)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.19.0->-r requirements3.txt (line 1)) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.19.0->-r requirements3.txt (line 1)) (4.0.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.23.2->-r requirements3.txt (line 3)) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai==1.23.2->-r requirements3.txt (line 3))\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.23.2->-r requirements3.txt (line 3))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.23.2->-r requirements3.txt (line 3)) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.23.2->-r requirements3.txt (line 3)) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.19.0->-r requirements3.txt (line 1)) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.19.0->-r requirements3.txt (line 1)) (2.0.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.2->-r requirements3.txt (line 7)) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.19.0->-r requirements3.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.19.0->-r requirements3.txt (line 1)) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.19.0->-r requirements3.txt (line 1)) (2024.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.2->-r requirements3.txt (line 7)) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.19.0->-r requirements3.txt (line 1)) (1.16.0)\n",
            "Installing collected packages: xxhash, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, h11, dill, scipy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, huggingface-hub, httpcore, scikit-learn, nvidia-cusolver-cu12, httpx, transformers, torch, openai, datasets, torchvision, sentence-transformers\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.11.4\n",
            "    Uninstalling scipy-1.11.4:\n",
            "      Successfully uninstalled scipy-1.11.4\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.20.3\n",
            "    Uninstalling huggingface-hub-0.20.3:\n",
            "      Successfully uninstalled huggingface-hub-0.20.3\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.40.1\n",
            "    Uninstalling transformers-4.40.1:\n",
            "      Successfully uninstalled transformers-4.40.1\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.2.1+cu121\n",
            "    Uninstalling torch-2.2.1+cu121:\n",
            "      Successfully uninstalled torch-2.2.1+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.17.1+cu121\n",
            "    Uninstalling torchvision-0.17.1+cu121:\n",
            "      Successfully uninstalled torchvision-0.17.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.24.4 which is incompatible.\n",
            "torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 2.2.2 which is incompatible.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.19.0 dill-0.3.8 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 huggingface-hub-0.22.2 multiprocess-0.70.16 numpy-1.24.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 openai-1.23.2 scikit-learn-1.3.2 scipy-1.10.1 sentence-transformers-2.7.0 torch-2.2.2 torchvision-0.17.2 transformers-4.40.0 xxhash-3.4.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "ee0ee567fd694739a5806c0d6d30a093"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv==1.0.1"
      ],
      "metadata": {
        "id": "d7SCeMEX9PA1",
        "outputId": "210abde5-5771-405c-806e-1df0245497c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv==1.0.1 in /usr/local/lib/python3.10/dist-packages (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"]=openai_api_key\n"
      ],
      "metadata": {
        "id": "sKf9ImQH9Wn_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recreate STS results"
      ],
      "metadata": {
        "id": "oDto3CAc-vr3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create x1 sentences (15,000 sentences)"
      ],
      "metadata": {
        "id": "MUnXs4aJ-7-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 dino.py --output_dir outputs \\\n",
        "--task_file task_specs/sts-x1.json \\\n",
        "--num_entries_per_label 2 \\\n",
        "--batch_size 1 \\\n",
        "--keep_outputs_without_eos \\\n",
        "--remove_duplicates \\\n",
        "--output_file_name sts-x1-default"
      ],
      "metadata": {
        "id": "m-ar4UTw_CGk",
        "outputId": "d5a9d5fe-639f-4480-9a06-c6686b60e117",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters: Namespace(output_dir='outputs', task_file='task_specs/sts-x1.json', model_name='gpt2-xl', max_output_length=40, decay_constant=100, top_p=0.9, top_k=5, output_file_name='sts-x1-default', input_file=None, input_file_type='plain', num_entries_per_input_and_label=None, num_entries_per_label=2, batch_size=1, remove_duplicates=True, remove_identical_pairs=False, keep_outputs_without_eos=True, allow_newlines_in_outputs=False, min_num_words=-1, min_num_tokens=-1, chat_completions=False, use_openai=False, no_cuda=False, seed=42, date='01/05/2024 02:52:24')\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/modeling_gpt2.py:1192: FutureWarning: `GPT2LMHeadModel.parallelize` is deprecated and will be removed in v5 of Transformers, you should load your model with `device_map='balanced'` in the call to `from_pretrained`. You can also provide your own `device_map` but it needs to be a dictionary module_name to device, so for instance {'transformer.h.0': 0, 'transformer.h.1': 1, ...}\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/modeling_gpt2.py:918: FutureWarning: `GPT2Model.parallelize` is deprecated and will be removed in v5 of Transformers, you should load your model with `device_map='balanced'` in the call to `from_pretrained`. You can also provide your own `device_map` but it needs to be a dictionary module_name to device, so for instance {'h.0': 0, 'h.1': 1, ...}\n",
            "  warnings.warn(\n",
            "Starting dataset generation with DINO...\n",
            "Dataset Entries: 100% 2/2 [00:12<00:00,  6.07s/it]\n",
            "Dataset generation complete, dataset contains 6 entries\n",
            "Done saving dataset to file 'outputs/sts-x1-default-dataset.jsonl'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 dino.py --output_dir outputs \\\n",
        "--task_file task_specs/sts-x2.json \\\n",
        "--input_file outputs/sts-x1-default-dataset.jsonl \\\n",
        "--input_file_type jsonl \\\n",
        "--num_entries_per_input_and_label 2 \\\n",
        "--output_file_name sts-default \\\n",
        "--remove_duplicates \\\n",
        "--remove_identical_pairs"
      ],
      "metadata": {
        "id": "Bk5kgm3rB8e6",
        "outputId": "8e26832d-5539-4aa1-9860-7d840074bf95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters: Namespace(output_dir='outputs', task_file='task_specs/sts-x2.json', model_name='gpt2-xl', max_output_length=40, decay_constant=100, top_p=0.9, top_k=5, output_file_name='sts-default', input_file='outputs/sts-x1-default-dataset.jsonl', input_file_type='jsonl', num_entries_per_input_and_label=2, num_entries_per_label=None, batch_size=None, remove_duplicates=True, remove_identical_pairs=True, keep_outputs_without_eos=False, allow_newlines_in_outputs=False, min_num_words=-1, min_num_tokens=-1, chat_completions=False, use_openai=False, no_cuda=False, seed=42, date='01/05/2024 02:51:42')\n",
            "Done loading 6 inputs from file 'outputs/sts-x1-default-dataset.jsonl'\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/modeling_gpt2.py:1192: FutureWarning: `GPT2LMHeadModel.parallelize` is deprecated and will be removed in v5 of Transformers, you should load your model with `device_map='balanced'` in the call to `from_pretrained`. You can also provide your own `device_map` but it needs to be a dictionary module_name to device, so for instance {'transformer.h.0': 0, 'transformer.h.1': 1, ...}\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/modeling_gpt2.py:918: FutureWarning: `GPT2Model.parallelize` is deprecated and will be removed in v5 of Transformers, you should load your model with `device_map='balanced'` in the call to `from_pretrained`. You can also provide your own `device_map` but it needs to be a dictionary module_name to device, so for instance {'h.0': 0, 'h.1': 1, ...}\n",
            "  warnings.warn(\n",
            "Starting dataset generation with DINO...\n",
            "Dataset Entries: 100% 6/6 [00:34<00:00,  5.82s/it]\n",
            "Dataset generation complete, dataset contains 32 entries\n",
            "Done saving dataset to file 'outputs/sts-default-dataset.jsonl'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ablations/modifications:\n",
        "\n"
      ],
      "metadata": {
        "id": "dvAAupWYBbfJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate with gpt3.5"
      ],
      "metadata": {
        "id": "pnlXqztbBr3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 dino.py --output_dir outputs \\\n",
        "--task_file task_specs/sts-x1.json \\\n",
        "--num_entries_per_label 2 \\\n",
        "--batch_size 1 \\\n",
        "--use_openai \\\n",
        "--chat_completions \\\n",
        "--model_name gpt-3.5-turbo-0125 \\\n",
        "--keep_outputs_without_eos \\\n",
        "--output_file_name sts-x1-gpt3.5 \\\n",
        "--remove_duplicates"
      ],
      "metadata": {
        "id": "EuSWViKl-1M0",
        "outputId": "9c4c1f42-9d72-41c3-f21f-cc4d9a404bc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters: Namespace(output_dir='outputs', task_file='task_specs/sts-x1.json', model_name='gpt-3.5-turbo-0125', max_output_length=40, decay_constant=100, top_p=0.9, top_k=5, output_file_name='sts-x1-gpt3.5', input_file=None, input_file_type='plain', num_entries_per_input_and_label=None, num_entries_per_label=2, batch_size=1, remove_duplicates=True, remove_identical_pairs=False, keep_outputs_without_eos=True, allow_newlines_in_outputs=False, min_num_words=-1, min_num_tokens=-1, chat_completions=True, use_openai=True, no_cuda=False, seed=42, date='01/05/2024 02:55:10')\n",
            "Using OpenAI's (gpt-3.5-turbo-0125) as generator. The following parameters are ignored: ['decay_constant', 'top_k']\n",
            "Starting dataset generation with DINO...\n",
            "Dataset Entries: 100% 2/2 [00:03<00:00,  1.94s/it]\n",
            "Dataset generation complete, dataset contains 6 entries\n",
            "Done saving dataset to file 'outputs/sts-x1-gpt3.5-dataset.jsonl'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 dino.py --output_dir outputs \\\n",
        "--task_file task_specs/sts-x2.json \\\n",
        "--input_file outputs/sts-x1-gpt3.5-dataset.jsonl \\\n",
        "--input_file_type jsonl \\\n",
        "--num_entries_per_input_and_label 2 \\\n",
        "--use_openai \\\n",
        "--chat_completions \\\n",
        "--model_name gpt-3.5-turbo-0125 \\\n",
        "--keep_outputs_without_eos \\\n",
        "--output_file_name sts-gpt3.5 \\\n",
        "--remove_duplicates \\\n",
        "--remove_identical_pairs"
      ],
      "metadata": {
        "id": "K10veJoAwRC1",
        "outputId": "aff47af8-3c45-47a6-864f-d67a86166f2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters: Namespace(output_dir='outputs', task_file='task_specs/sts-x2.json', model_name='gpt-3.5-turbo-0125', max_output_length=40, decay_constant=100, top_p=0.9, top_k=5, output_file_name='sts-gpt3.5', input_file='outputs/sts-x1-gpt3.5-dataset.jsonl', input_file_type='jsonl', num_entries_per_input_and_label=2, num_entries_per_label=None, batch_size=None, remove_duplicates=True, remove_identical_pairs=True, keep_outputs_without_eos=True, allow_newlines_in_outputs=False, min_num_words=-1, min_num_tokens=-1, chat_completions=True, use_openai=True, no_cuda=False, seed=42, date='01/05/2024 02:55:18')\n",
            "Done loading 6 inputs from file 'outputs/sts-x1-gpt3.5-dataset.jsonl'\n",
            "Using OpenAI's (gpt-3.5-turbo-0125) as generator. The following parameters are ignored: ['decay_constant', 'top_k']\n",
            "Starting dataset generation with DINO...\n",
            "Dataset Entries: 100% 6/6 [00:22<00:00,  3.69s/it]\n",
            "Dataset generation complete, dataset contains 34 entries\n",
            "Done saving dataset to file 'outputs/sts-gpt3.5-dataset.jsonl'\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}